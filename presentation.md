# 研究進捗報告：ハイブリッド異常検知モデルの構築

**発表者: (ご自身の名前)**
**日付: 2025-11-18**

---

## 1. はじめに：これまでの歩みと残された課題

### 本研究の目的（再掲）
*   オートエンコーダ(AE)の「再構成誤差」だけでは見逃してしまう「巧妙な異常」を、サポートベクターマシン(SVM)による「パターン分類」を組み合わせて検知する、**ハイブリッドモデル**の有効性を検証する。

### これまでの歩み
1.  **【Step 1】ベースライン構築と"見逃し"の証明**
    *   **内容:** 「正常な通信データ」のみで単純なAEを学習させ、その限界を評価しました。
    *   **結果:** 異常検知率は**76%**に留まり、**異常全体の24%（約3,000件）を見逃す**ことを定量的に確認しました。

2.  **【Step 2】AEの進化と評価の最適化**
    *   **内容:** 次に、AE単体の性能を向上させるため、**先行研究（C-2-10）で示されていた**、正常・異常が混在したデータから学習できる**「学習識別再構成(LDR-AE)」**を実装しました。
    *   **成果:** 当初、評価方法がモデルに合わず性能が低下しましたが、評価に用いる「閾値」を**Youden's J-statistic**で最適化することで、異常検知率を**80%**まで向上させることに成功しました。

### 残された課題
*   AE単体の性能は向上しましたが、それでもまだ**異常全体の20%（約2,600件）を見逃しています。**
*   このAEだけでは捉えきれない異常を、第二の専門家である**SVMが補完的に検知できるのか？** これが、今回ご報告するStep3のテーマです。

---

## 2. 本日の報告内容：Step 3 ハイブリッドモデル

*   **【Step 3】ハイブリッドモデルの構築と最終評価**
    *   AEとSVMを連携させた本研究の最終モデルを構築し、その性能をベースラインおよびLDR-AE単体モデルと比較・評価します。

---

## 3. Step 3: ハイブリッドモデルによる最終決戦

### 3-1. 手法：AEとSVMの連携
*   **目的:** AEが見逃す「パターンそのものの異常性」を、SVMで補完的に検知する。
*   **実装 (`train_hybrid_svm.py`):**
    1.  **潜在変数の抽出:** 学習済みのLDR-AEモデルのエンコーダ部分を使い、訓練データから32次元の「潜在変数」を抽出します。
    2.  **特徴量の標準化:** SVMの性能を最大化するため、`StandardScaler` を用いて潜在変数のスケールを標準化します。
    3.  **SVMの学習:** 標準化された潜在変数を特徴量、元の正解ラベルを教師として `SVC` を学習させます。
        *   `kernel='rbf'`: 非線形なパターン分離を可能にします。
        *   `class_weight='balanced'`: データ数の不均衡を考慮し、少数派（異常）クラスの重要度を上げます。
        *   `probability=True`: 後段のスコア統合のため、「異常である確率」を計算できるようにします。

### 3-2. ハイブリッド判定ロジック (`evaluate_hybrid_model.py`)
1.  **2指標の算出:** テストデータに対し、以下の2つのスコアを計算します。
    *   **スコアA (形状異常):** AEによる「再構成誤差」。
    *   **スコアB (パターン異常):** AEの潜在変数をSVMで分類し「異常である確率」。
2.  **スコア統合:**
    *   2つのスコアを `MinMaxScaler` で `0~1` の範囲に正規化します。
    *   `Hybrid Score = (正規化後スコアA + 正規化後スコアB) / 2` として、最終的な異常スコアを算出します。
3.  **最終判定:** このハイブリッドスコアに対し、再びYouden's J-statisticで最適な閾値を決定し、異常判定を行います。

---

## 4. 本研究における評価指標

本研究では、モデルの性能を多角的に評価するため、以下の4つの指標を採用します。特に、本タスクのような**異常データが正常データに比べて極端に少ない（不均衡な）状況**では、単一の指標ではモデルの真の性能を見誤る可能性があるためです。

*   **真陽性 (TP):** 異常を正しく「異常」と予測。
*   **偽陽性 (FP):** 正常を誤って「異常」と予測 (誤検知)。
*   **真陰性 (TN):** 正常を正しく「正常」と予測。
*   **偽陰性 (FN):** 異常を誤って「正常」と予測 (見逃し)。

### 1. 正解率 (Accuracy)
*   **意味:** 全てのデータのうち、モデルが正しく分類できた割合。
*   **計算式:** `(TP + TN) / (TP + FP + TN + FN)`
*   **役割:** モデル全体の総合的な正しさを測る基本的な指標。

### 2. 異常再現率 (Anomaly Recall)
*   **意味:** 実際に異常であるデータのうち、モデルがどれだけ「異常」と正しく検出できたかの割合。
*   **計算式:** `TP / (TP + FN)`
*   **選定理由:** **「異常の見逃し」をどれだけ防げたか**を示す最重要指標。セキュリティの文脈では、攻撃を見逃すことの被害が大きいため、特に重視されます。

### 3. 異常適合率 (Anomaly Precision)
*   **意味:** モデルが「異常」と予測したデータのうち、実際に異常であったものの割合。
*   **計算式:** `TP / (TP + FP)`
*   **選定理由:** **「誤検知」の少なさ**を示します。誤検知が多いと、アラートへの信頼性が低下し、運用コストが増大するため、これも重要な指標です。

### 4. F1スコア (F1-Score)
*   **意味:** 再現率と適合率のバランスを取った指標（調和平均）。
*   **計算式:** `2 * (Precision * Recall) / (Precision + Recall)`
*   **選定理由:** 再現率と適合率はトレードオフの関係にあるため、両者をバランス良く評価するために採用します。**モデルの総合的な異常検知性能**を判断するのに適しています。

---

## 5. 最終結果：ハイブリッドモデルの有効性

3つのモデルの最終的な性能を比較します。

| モデル                 | Accuracy  | **Anomaly Recall** | Anomaly Precision | F1-Score (Anomaly) |
| :--------------------- | :-------- | :----------------- | :---------------- | :----------------- |
| ベースラインAE (前回)  | 0.843     | **0.76**           | 0.95 (※参考)      | 0.84               |
| LDR-AE (単体)          | 0.835     | **0.80**           | 0.90              | 0.85               |
| **ハイブリッドモデル** | **0.897** | **0.92**           | 0.90              | **0.91**           |

<br>

### 異常の見逃し件数の比較
*   **ベースラインAE:** 約 **3,000** 件
*   **LDR-AE:** 約 **2,600** 件
*   **ハイブリッドモデル:** 約 **975** 件

### 結論
*   ハイブリッドモデルは、**異常検知率92%**、F1スコアも0.91という、極めて高く、かつバランスの取れた性能を達成しました。
*   ベースラインAEが見逃した**約3,000件の異常のうち、2,000件以上を新たに検知**することに成功。見逃し件数を約1/3にまで削減しました。
*   **AEの「形状」とSVMの「パターン」という二重の視点を持つ、という本研究の仮説は、実験的に証明されました。**

---

## 6. まとめと今後の展望

### 今回の成果
*   AEの学習・評価方法を最適化し、単体性能を向上させました (異常検知率: 76% → 80%)。
*   最終的に、AEとSVMを組み合わせた**ハイブリッドモデル**を構築し、異常検知率を**92%**まで大幅に向上させることに成功しました。

### 今後の展望
*   **ハイブリッドスコアの最適化:**
    *   現在は単純平均でスコアを統合していますが、AEスコアとSVMスコアの重みを調整することで、さらなる性能向上が期待できます。
*   **SVMのさらなるチューニング:**
    *   SVM自体のハイパーパラメータ（`C`や`gamma`など）を`GridSearchCV`などで探索・最適化することで、モデル全体の精度向上を目指します。
*   **他データセットへの応用:**
    *   他の種類のネットワーク攻撃データや、全く異なるドメインのデータに対しても本アプローチが有効か検証します。

---

## ご清聴ありがとうございました




