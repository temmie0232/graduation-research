# プロジェクト計画 (Project_Plan.md)

## プロジェクト目標
オートエンコーダ（AE）の「再構成能力」とサポートベクターマシン（SVM）の「パターン分類能力」を組み合わせたハイブリッドモデルを構築し、ラベルなしネットワークトラフィック（NSL-KDDデータセット）に対する異常検知の精度を最大化する。

---

## マイルストーン 1 (第1回発表会)
**テーマ: 基礎研究とベースラインモデルの構築**
**ゴール:** 関連研究の理解を深め、データセットを準備し、比較対象となる「単純なオートエンコーダ」による異常検知を実装・評価する。

### タスク一覧
* **1-1. 関連研究の精読**
    * [cite_start][ ] **C-2-10 [cite: 269] [cite_start]の精読:** 「学習識別再構成」 [cite: 280] [cite_start]のアルゴリズム（特に判別ラベリング [cite: 282] [cite_start]と再構成学習 [cite: 286]）を完全に理解する。
    * [cite_start][ ] **C-2-22 [cite: 3417] [cite_start]の精読:** SVM [cite: 3422] [cite_start]の活用法と、データスケーリング [cite: 3428] [cite_start]の重要性（特に外れ値への対処法 [cite: 3439]）を理解する。
* **1-2. 開発環境の構築**
    * [ ] Python プログラミング環境のセットアップ。
    * [ ] 必要なライブラリのインストール (PyTorch, scikit-learn, Pandas, NumPy, Matplotlib)。
* **1-3. データセットの準備と前処理**
    * [cite_start][ ] NSL-KDDデータセット [cite: 308, 3439] をダウンロードする。
    * [ ] `Pandas` を使用してデータを読み込む。
    * [ ] **前処理スクリプトの作成:**
        * [cite_start][ ] カテゴリカル特徴量（`protocol_type` など）を数値に変換する（One-Hotエンコーディング [cite: 3445]）。
        * [cite_start][ ] 数値特徴量をスケーリング [cite: 3428] [cite_start]する（例: `StandardScaler` [cite: 3432] [cite_start]や `MinMaxScaler` [cite: 3430]）。
* **1-4. ベースラインモデル (単純AE) の実装**
    * [ ] PyTorch を使用して、基本的なオートエンコーダ（エンコーダ・デコーダ）を実装する。
    * [cite_start][ ] **正常データのみ**を使用してAEを学習させる [cite: 279]。
* **1-5. ベースラインモデルの評価**
    * [cite_start][ ] 学習済みモデルにテストデータ（正常・異常両方）を入力し、「再構成誤差」 [cite: 279] を計算する。
    * [ ] 正常データと異常データの再構成誤差の分布をグラフで可視化し、閾値を設定して異常検知を行う。
    * [cite_start][ ] 性能を評価（正答率 [cite: 321][cite_start], 混同行列 [cite: 321]）し、ベースラインの結果として記録する。
* **1-6. 第1回発表準備**
    * [ ] 上記 1-1 〜 1-5 の進捗と結果をスライドにまとめる。

---

## マイルストーン 2 (第2回発表会)
**テーマ: 中核技術 (学習識別再構成 AE) の実装と評価**
[cite_start]**ゴール:** 研究の核となる「学習識別再構成」アルゴリズム [cite: 280] を実装し、その単体性能をベースラインと比較・評価する。

### タスク一覧
* **2-1. 「学習識別再構成」アルゴリズムの実装**
    * [cite_start][ ] C-2-10 [cite: 269] に基づき、AEの学習プロセスに以下の機能を追加する。
        * [cite_start][ ] **判別ラベリング処理[cite: 282]:** ミニバッチ内の各データの再構成誤差に基づき、一時的な「正常/異常」ラベルを推定するロジックを実装する。
        * [cite_start][ ] **再構成学習処理[cite: 286]:** 正常と推定されたデータのみで再構成誤差を最小化するよう学習するロジックを実装する。
* **2-2. 学習識別再構成 AE の学習**
    * [cite_start][ ] **ラベルなし混合データ**（正常データと異常データが混在した状態） [cite: 301] を用いて、実装したモデルを学習させる。
* **2-3. 性能評価 (AE単体)**
    * [cite_start][ ] 学習済みモデルから「**指標A (再構成誤差)**」 [cite: 279] [cite_start]を抽出し、異常検知の性能（正答率, 混同行列 [cite: 321]）を評価する。
    * [ ] 学習済みモデルの中間層から「**指標B (潜在変数)**」を抽出する機能を追加実装する（次のフェーズで使用）。
* **2-4. 比較考察**
    * [ ] マイルストーン1（単純AE）の結果と、今回の結果を比較する。
    * [ ] ラベルなし混合データで学習したにもかかわらず、ベースラインと同等またはそれ以上の性能が出ることを確認する。
* **2-5. 第2回発表準備**
    * [ ] 実装したアルゴリズムの解説と、ベースラインとの性能比較結果をスライドにまとめる。

---

## マイルストーン 3 (第3回発表会)
**テーマ: ハイブリッドモデルの構築 (AE + SVM)**
**ゴール:** 第2の分類器 (SVM) を実装し、AEと組み合わせたハイブリッドモデルを完成させる。

### タスク一覧
* **3-1. SVM 分類器の実装**
    * [cite_start][ ] C-2-22 [cite: 3417] [cite_start]を参考に、`scikit-learn` を用いて SVM [cite: 3422] 分類器を実装する。
* **3-2. SVM の学習**
    * [ ] マイルストーン2で学習させたAEを使用し、学習データセット全体から「**指標B (潜在変数)**」を抽出する。
    * [ ] NSL-KDDデータセットの**正解ラベル**（*この学習のみ教師あり*）と潜在変数をペアにして、SVMに学習させる。
    * *（代替案: AEの判別ラベリング結果を教師データとしてSVMを学習させることも検討）*
* **3-3. ハイブリッド判定ロジックの実装**
    * [ ] 未知のテストデータが入力された際に、以下の2つのスコアを算出するロジックを実装する。
        1.  [cite_start]**スコアA:** AEによる「再構成誤差スコア」 [cite: 279]。
        2.  **スコアB:** AEから抽出した潜在変数をSVMに入力して得られる「パターン異常スコア」。
    * [ ] 2つのスコアを統合（例: 重み付け平均、論理和など）し、最終的な異常判定を下すアルゴリズムを設計・実装する。
* **3-4. ハイブリッドモデルの暫定評価**
    * [ ] テストデータを用いてハイブリッドモデルの性能を暫定的に評価し、マイルストーン2の結果（AE単体）と比較する。
* **3-5. 第3回発表準備**
    * [ ] SVMの導入プロセスと、ハイブリッド判定のロジック、暫定的な性能向上結果をスライドにまとめる。

---

## マイルストーン 3.5 (追加実験)
**テーマ: モデルの正当性強化と比較実験**
**ゴール:** 教授のアドバイスに基づき、提案モデル（AE+SVM）の構成要素（入力データ・次元数・カーネル）が最適であることを証明するための比較データを収集する。

### タスク一覧
* **3.5-1. SVMへの入力データ比較実験 (生データ vs 潜在変数)**
    * **目的:** 「AEを経由せず、生データをそのままSVMに入れた方が良いのではないか？」という疑問に答え、提案手法（潜在変数利用）の優位性や特性を明らかにする。
    * [ ] `src/train_raw_svm.py` を作成する。
        * 前処理済みの生データ `X_train.csv` (119次元) を直接SVMに学習させる。
    * [ ] `src/evaluate_raw_svm.py` を作成し、テストデータに対する性能を計測する。
    * [ ] **比較検証:** マイルストーン3で作成した「ハイブリッドモデル（潜在変数入力）」と、今回の「生データ入力SVM」の性能（F1スコア, Recall, 計算時間など）を直接比較し、AEによる次元圧縮の有効性を評価する。

* **3.5-2. オートエンコーダの次元数比較実験**
    * **目的:** 中間層の次元数（現在は32）が適切であることを証明する。
    * [ ] `src/train_baseline_ae.py` を改造し、中間層 (`HIDDEN_DIM_2`) を可変にする。
    * [ ] 以下の3パターンでAEを学習させ、それぞれの再構成誤差の減少推移と最終的な異常検知精度を比較する。
        * **パターンA:** 16次元 (圧縮率 高)
        * **パターンB:** 32次元 (現在)
        * **パターンC:** 64次元 (圧縮率 低)
    * [ ] 各パターンの結果を表にまとめる（「32次元がバランスが良い」等の結論を導く）。

* **3.5-3. SVMカーネルの比較実験 (非線形対応)**
    * **目的:** 線形SVM (`LinearSVC`) よりも非線形カーネルの方が精度が出る可能性を検証する。
    * [ ] `src/train_hybrid_svm.py` を改造し、RBFカーネル（または `Nystroem` 近似による高速化版）を実装する。
    * [ ] 線形カーネルと非線形カーネルで、ハイブリッドモデルの異常検知精度（特にRecall）がどう変化するか比較する。

* **3.5-4. 比較実験結果の統合**
    * [ ] 上記3つの実験結果を統合し、マイルストーン4（卒論執筆）で「考察」に使用するためのグラフ・表を作成する。
        * **作成物1:** 入力データ別比較表 (生データSVM vs 潜在変数SVM)
        * **作成物2:** 次元数別感度分析表 (16 vs 32 vs 64)
        * **作成物3:** カーネル別比較表 (Linear vs RBF)
---

## マイルストーン 4 (第4回発表会・最終提出)
**テーマ: 最終評価、詳細分析、論文執筆**
**ゴール:** 提案モデルの有効性を多角的に証明し、研究成果を卒業論文として完成させる。

### タスク一覧
* **4-1. 最終性能比較実験**
    * [ ] 以下の3〜4モデルについて、同一のテストデータセットで厳密な性能比較を行う。
        1.  [cite_start]ベースライン (単純AE) [cite: 279]
        2.  [cite_start]AE単体 (学習識別再構成) [cite: 280]
        3.  [cite_start]SVM単体 (潜在変数のみで分類) [cite: 3422]
        4.  **提案ハイブリッドモデル (AE + SVM)**
    * [cite_start][ ] 評価指標（正答率、Precision, Recall, F1スコア、混同行列 [cite: 321]）を用いて、各モデルの性能を定量的に比較する表を作成する。
* **4-2. 詳細分析と考察**
    * [ ] **検知失敗事例の分析:**
        * AE単体では見逃したが、ハイブリッドモデルでは検知できた異常は何か？
        * 逆に、ハイブリッドモデルでも見逃した異常は何か？ その特徴は？
    * [ ] **判断不一致の分析:** AE（再構成誤差）とSVM（パターン）で判断が分かれた事例を抽出し、なぜ食い違いが起きたのかを考察する。
* **4-3. 卒業論文の執筆**
    * [ ] **[はじめに]:** 研究背景、目的、アプローチ (概要の再構成)
    * [cite_start][ ] **[関連研究]:** C-2-10 [cite: 269] [cite_start]と C-2-22 [cite: 3417] の内容をまとめる。
    * [cite_start][ ] **[提案手法]:** ハイブリッドモデルのアーキテクチャ、AE [cite: 280] [cite_start]とSVM [cite: 3422] の役割、判定ロジックを詳細に記述する。
    * [cite_start][ ] **[実験]:** 使用データセット [cite: 308, 3439][cite_start]、前処理 [cite: 3428, 3445][cite_start]、評価方法 [cite: 321] を記述する。
    * [ ] **[結果と考察]:** 4-1の比較結果（表・グラフ）と 4-2の詳細分析を記述する。
    * [ ] **[おわりに]:** 研究の結論と今後の展望をまとめる。
* **4-4. 第4回発表準備**
    * [ ] 卒業論文の要点をスライドにまとめ、最終発表を行う。