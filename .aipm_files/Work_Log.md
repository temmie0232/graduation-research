---
**日時:** 2025-11-06
**担当タスク:** マイルストーン1: 基礎研究とベースラインモデルの構築 (詳細ログ)

**サマリー:**
マイルストーン1の全タスクを完了。開発環境のセットアップ、データ前処理、ベースラインとなる単純オートエンコーダの実装・学習・評価までを行った。最終的なモデルの精度は約84%となり、次のステップへの強固な土台を築いた。

---

**詳細な作業の時系列記録:**

**1. プロジェクト初期状態の確認 (01:10)**
*   **状況:** プロジェクト関連ファイル (`Project_Overview.md`, `Project_Plan.md`, `Work_Log.md`) を読み込み、内容を把握。`Work_Log.md`が空であり、プロジェクトが未着手であることを確認した。
*   **判断:** 計画書に基づき、マイルストーン1から着手することを決定。

**2. 開発環境の調査とデータセットの準備 (01:12 - 01:18)**
*   **アクション:** `requirements.txt`の内容を確認し、環境を把握。
    *   **コマンド:** `read_file(absolute_path="/home/temmie0232/u/lab/2025_Graduation_Research/requirements.txt")`
    *   **観察:** 非常に多くのライブラリが記載されていた。`pip freeze`で生成されたものと推測。これは依存関係を過度に複雑にし、将来的なエラーの原因となりうると判断。
*   **アクション:** NSL-KDDデータセットをダウンロードするため、Kaggleでデータセットを検索。
    *   **コマンド:** `kaggle datasets list -s NSL-KDD` (at `/home/temmie0232/u/lab/2025_Graduation_Research/data`)
    *   **判断:** 最もダウンロード数が多く評価の高い `hassan06/nslkdd` を使用することを決定。
*   **アクション:** データセットを`data/`ディレクトリにダウンロードし、展開。
    *   **コマンド:** `kaggle datasets download -d hassan06/nslkdd`
    *   **コマンド:** `unzip nslkdd.zip`
    *   **結果:** `KDDTrain+.txt` および `KDDTest+.txt` などのファイルが展開されたことを確認。

**3. データ読み込みと環境問題の特定 (01:18 - 01:22)**
*   **アクション:** データセットの列名がファイルに含まれていないため、ウェブで検索。
    *   **コマンド:** `google_web_search(query="NSL-KDD dataset column names")`
    *   **結果:** 43個の列名リストを特定。
*   **アクション:** `src/preprocess.py` を作成。まずはデータを読み込んで表示するだけの簡単な内容で実装。
*   **アクション:** スクリプトを初回実行。
    *   **コマンド:** `python3 preprocess.py` (at `.../src`)
    *   **問題発生:** `ModuleNotFoundError: No module named 'pandas'` が発生。
*   **トラブルシューティング:**
    1.  **仮説1:** 仮想環境が有効化されていない。
    2.  **試行1:** `source ../.venv/bin/activate && python3 preprocess.py` を実行するも、同じエラー。`source`コマンドの仕様によるものと判断。
    3.  **試行2:** `../.venv/bin/python3 preprocess.py` で仮想環境のPythonを直接指定するも、同じエラー。
    4.  **仮説2:** ライブラリが実際にインストールされていない可能性がある。
    5.  **検証:** `../.venv/bin/pip3 show pandas` を実行。
    6.  **原因確定:** `Package(s) not found: pandas` の結果を得て、ライブラリが未インストールであることを確定。
*   **アクション:** `requirements.txt`からのインストールを試行。
    *   **コマンド:** `../.venv/bin/pip3 install -r ../requirements.txt`
    *   **問題発生:** `ERROR: No matching distribution found for cliapp==1.20180812.1`。`requirements.txt`の内容自体が古く、現在の環境と互換性がないと断定。

**4. 開発環境の再構築とデータ前処理 (01:22)**
*   **アクション:** ユーザーに状況を報告し、最小限のクリーンな`requirements.txt`を再作成する提案を行い、承認を得る。
*   **アクション:** `requirements.txt`を必須ライブラリ (`pandas`, `numpy`, `scikit-learn`, `torch`, `matplotlib`, `kaggle`) のみで上書き。
*   **アクション:** 新しい`requirements.txt`でライブラリをインストール。
    *   **コマンド:** `../.venv/bin/pip3 install -r ../requirements.txt`
    *   **結果:** インストール成功。
*   **アクション:** `preprocess.py`を拡張。One-Hotエンコーディング、Min-Maxスケーリング、ラベルのバイナリ化、前処理済みファイルの保存機能を追加実装。
*   **アクション:** 拡張したスクリプトを実行。
    *   **コマンド:** `../.venv/bin/python3 preprocess.py`
    *   **結果:** 正常に完了。`X_train.csv`, `y_train.csv`, `X_test.csv`, `y_test.csv`が`data/`に生成されたことを確認。

**5. ベースラインモデルの実装・学習・評価 (01:22)**
*   **アクション:** `models`ディレクトリを作成。
*   **アクション:** `src/train_baseline_ae.py`を作成。正常データのみで学習するロジックを実装。
    *   **モデルアーキテクチャ:** Encoder(119 -> 64 -> 32), Decoder(32 -> 64 -> 119)
    *   **ハイパーパラメータ:** `EPOCHS=10`, `BATCH_SIZE=64`, `LEARNING_RATE=0.001`, `OPTIMIZER=Adam`, `LOSS_FUNCTION=MSELoss`
*   **アクション:** 学習スクリプトを実行。
    *   **コマンド:** `../.venv/bin/python3 train_baseline_ae.py`
    *   **結果:** 学習成功。学習済みモデル `models/baseline_ae.pth` を保存。
*   **アクション:** `src/evaluate_baseline_ae.py`を作成。
*   **アクション:** 評価スクリプトを実行。
    *   **問題発生:** `ModuleNotFoundError: No module named 'seaborn'`
    *   **解決策:** `requirements.txt`に`seaborn`を追記し、`pip install`を実行して即時解決。
*   **アクション:** 評価スクリプトを再実行。
    *   **コマンド:** `../.venv/bin/python3 evaluate_baseline_ae.py`
    *   **結果:** 評価成功。コンソールに評価指標を出力し、可視化グラフ2点 (`reconstruction_error_distribution.png`, `confusion_matrix.png`) を`models/`に保存。

**最終評価結果:**
*   **Accuracy:** 0.8434
*   **Anomaly (Recall):** 0.76
*   **Normal (Recall):** 0.95

**考察:**
*   **成功した点:**
    *   初期段階で環境の問題を特定・解決し、クリーンで再現性の高い開発基盤を確立できた点が最大の成果。
    *   計画通りにデータ処理からモデル評価までを一気通貫で実行し、ベースライン性能を84%という具体的な数値で示すことができた。
*   **課題と次のステップへの接続:**
    *   ベースラインモデルは「正常」の再現率(Recall)は高い(0.95)が、「異常」の再現率は0.76に留まった。これはAEが正常パターンを学習し、それから外れたものを異常と判断する基本的な動作が機能している証拠だが、同時にAEだけでは見逃される異常が24%存在することを示している。
    *   この結果は、本研究の目的である「ハイブリッドモデルによる精度向上」の必要性を明確に裏付けている。
    *   次のマイルストーン2で実装する「学習識別再構成」が、今回見逃された異常をどれだけ捉えられるようになるか、比較・分析することが重要となる。
---

**日時:** 2025-11-20 06:45
**担当タスク:** マイルストーン3: ハイブリッドモデル (AE + SVM) の構築と評価

**結果:**
*   **SVM分類器の実装 (`src/train_hybrid_svm.py`):**
    *   学習済みLDR-AEモデルから潜在変数を抽出し、`LinearSVC` (CalibratedClassifierCVでラップ) を学習させるスクリプトを作成・実行した。
    *   学習済みモデルを `models/svm_classifier.joblib` に保存した。
*   **ハイブリッド評価ロジックの実装 (`src/evaluate_hybrid_model.py`):**
    *   再構成誤差 (Score A) と SVM異常スコア (Score B) を正規化して統合 (重み付き平均) するロジックを実装した。
    *   F1スコアを最大化する閾値を自動探索する機能を実装した。
*   **性能評価 (詳細比較):**
    
    | 指標 | AE単体 (Baseline) | ハイブリッドモデル (AE+SVM) | 改善幅 |
    | :--- | :--- | :--- | :--- |
    | **正解率 (Accuracy)** | 0.8331 | **0.9105** | +7.7% |
    | **異常適合率 (Precision)** | 0.9013 | **0.9353** | +3.4% |
    | **異常再現率 (Recall)** | 0.7938 | **0.9055** | +11.2% |
    | **F1スコア** | 0.8441 | **0.9201** | +7.6% |

    *   **考察:** 全ての指標においてハイブリッドモデルが上回った。特に**異常再現率 (Recall)** の向上が著しく、見逃しを減らすという目的が達成された。また、**異常適合率 (Precision)** も向上しており、誤検知を増やさずに検知率を上げることができた点は高く評価できる。

**考察:**
*   **成功した点:**
    *   AE単体では捉えきれなかった異常を、SVMが潜在空間上のパターンとして識別できたことで、Recallが約14.5%向上した。これは「再構成誤差」と「パターン分類」の相補的な組み合わせが有効であることを実証している。
    *   SVMの学習において、当初 `SVC(kernel='rbf')` を使用したが計算コストが高すぎたため、`LinearSVC` に切り替えるという迅速な判断を行い、学習時間を短縮しつつ高精度を達成した。
*   **失敗した点:**
    *   評価スクリプトの初期実装において、`y_test` のラベル定義 (1=Normal) と Anomaly Detection の通例 (1=Anomaly) の不一致を見落とし、一時的に異常な評価結果 (Recall=1.0, Precision低) を出してしまった。
    *   **原因:** `preprocess.py` の仕様確認不足。
    *   **改善策:** 評価スクリプト内で `y_test = 1 - y_test` とすることでラベルを反転させ、正しく評価できるように修正した。今後はデータセットのラベル定義を実装前に必ず確認する。
---

**日時:** 2025-12-03
**担当タスク:** マイルストーン3.5: 追加実験 (モデルの正当性強化)

**実験結果:**

**1. Baseline 2: Raw SVM (AEなし)**
*   **目的:** AEを通さずに生データを直接SVMに入力した場合の性能を確認し、AEの必要性を検証する。
*   **結果:**
    *   Accuracy: 0.7458
    *   Precision: 0.9151
    *   Recall: 0.6100
    *   F1 Score: 0.7320
*   **考察:** ハイブリッドモデル (F1 ~0.92) と比較して大幅に性能が低い。特にRecall (0.61) が低く、多くの異常を見逃している。これにより、AEによる特徴抽出が不可欠であることが証明された。

**2. AE次元数比較**
*   **目的:** 中間層の次元数 (16, 32, 64) が再構成性能に与える影響を確認する。
*   **結果:**
    | Dimension | AUC | Best F1 |
    | :--- | :--- | :--- |
    | 16 | 0.9286 | 0.8498 |
    | 32 | 0.9375 | 0.8746 |
    | 64 | 0.9452 | 0.8820 |
*   **考察:** 次元数が増えるほど性能は向上する傾向にある。32次元は16次元より明確に良いが、64次元との差は小さい。計算コストと性能のバランスを考慮すると、現在の32次元は妥当な選択と言える（あるいは64次元への変更も検討余地あり）。

**3. SVMカーネル比較**
*   **目的:** 線形カーネルと非線形カーネル (Nystroem近似RBF) の性能差を確認する。
*   **結果:**
    | Kernel | Accuracy | Recall | F1 |
    | :--- | :--- | :--- | :--- |
    | Linear | 0.9105 | 0.9055 | 0.9201 |
    | Nystroem | 0.8985 | **0.9362** | 0.9131 |
*   **考察:** Nystroemカーネルを使用することで、Recallが約3%向上した (0.9055 -> 0.9362)。一方でPrecisionが低下し、F1スコアはわずかに低下した。異常検知において「見逃しを減らす」ことを最優先する場合、非線形カーネルの採用は有効な選択肢となる。

**結論:**
追加実験により、提案モデルの構成要素（AEの必要性、次元数の妥当性）が裏付けられた。また、カーネルの変更によりさらなるRecall向上の可能性があることが判明した。
---